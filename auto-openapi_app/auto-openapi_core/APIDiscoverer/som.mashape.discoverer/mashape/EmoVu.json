{"swagger":"2.0","info":{"title":"EmoVu","description":"Deep Learning-based emotion recognition software that reads  facial micro-expressions in real-time with regular cameras.","contact":{"name":"eyeris","url":"http://www.eyeristech.com"},"version":null,"x-logo":"https://s3.amazonaws.com/mashape-production-logos/apis/53aa583fe4b07e1f4ebebbc8_medium","x-mashape-categories":["Other"],"x-origin":{"format":"mashape","url":"https://market.mashape.com/eyeris/emovu-1"}},"host":"eyeris-emovu1.p.mashape.com","basePath":"","paths":{"/api/image/":{"post":{"description":"Use the image endpoint to extract age, gender, emotion, face recognition results and more from static images. All common image formats including .jpg, .bmp, .png, .tif, and .pgm are supported. For a detailed description visit http://emovu.com/docs/html/web_api.htm.","operationId":"image","consumes":["application/json"],"produces":["application/json"],"responses":{"200":{"description":null,"schema":"#/definitions/Resource"}}}},"/api/imageframe/":{"post":{"description":"Use the imageframe endpoint to extract age, gender, emotion, face recognition results and more from an image sequence. The api response from the previous frame should be provided as an input parameter to process the current frame in order to avoid invoking the costly face detection process. For a detailed description visit http://emovu.com/docs/html/web_api.htm.","operationId":"imageframe","consumes":["application/json"],"produces":["application/json"],"responses":{"200":{"description":null,"schema":"#/definitions/Resource"}}}},"/api/video/":{"post":{"description":"Use the video endpoint to extract age, gender, emotion, face recognition results and more from video files. All common video formats including .avi, .flv, .mpg, .mov, and .mp4 are supported. For a detailed description visit http://emovu.com/docs/html/web_api.htm.","operationId":"video","consumes":["application/json"],"produces":["application/json"],"responses":{"200":{"description":null,"schema":"#/definitions/Resource"}}}}},"definitions":{"Resource":{"type":"object","properties":{"ProcessingTime":{"type":"integer"},"Tracked":{"type":"string"},"FaceAnalysisResults":{"type":"array","items":{"$ref":"#/definitions/FaceAnalysisResult"}}}},"IdentityResult":{"type":"object","properties":{"Identity":{"type":"integer"},"Computed":{"type":"string"},"Confidence":{"type":"integer"}}},"HeadPose":{"type":"object","properties":{"Pitch":{"type":"integer"},"Roll":{"type":"integer"},"Yaw":{"type":"integer"}}},"FaceTrackerResult":{"type":"object","properties":{"TrackingId":{"type":"integer"},"FaceRectangle":{"$ref":"#/definitions/FaceRectangle"},"HeadPose":{"$ref":"#/definitions/HeadPose"}}},"AgeGroupResult":{"type":"object","properties":{"AgeGroup":{"type":"string"},"Computed":{"type":"string"},"Confidence":{"type":"integer"}}},"MetricResult":{"type":"object","properties":{"Attention":{"type":"integer"},"Computed":{"type":"string"},"Expressiveness":{"type":"integer"},"NegativeMood":{"type":"integer"},"PositiveMood":{"type":"integer"},"Valence":{"type":"integer"}}},"FaceRectangle":{"type":"object","properties":{"Height":{"type":"integer"},"Left":{"type":"integer"},"Top":{"type":"integer"},"Width":{"type":"integer"}}},"EmotionResult":{"type":"object","properties":{"Anger":{"type":"integer"},"Computed":{"type":"string"},"Disgust":{"type":"integer"},"Fear":{"type":"integer"},"Joy":{"type":"integer"},"Neutral":{"type":"integer"},"Sadness":{"type":"integer"},"Surprise":{"type":"integer"}}},"GenderResult":{"type":"object","properties":{"Computed":{"type":"string"},"Confidence":{"type":"integer"},"Gender":{"type":"string"}}},"FaceAnalysisResult":{"type":"object","properties":{"AgeGroupResult":{"$ref":"#/definitions/AgeGroupResult"},"EmotionResult":{"$ref":"#/definitions/EmotionResult"},"FaceTrackerResult":{"$ref":"#/definitions/FaceTrackerResult"},"GenderResult":{"$ref":"#/definitions/GenderResult"},"IdentityResult":{"$ref":"#/definitions/IdentityResult"},"MetricResult":{"$ref":"#/definitions/MetricResult"}}}}}